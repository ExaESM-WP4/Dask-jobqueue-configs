
jobqueue:

  juwels-jobqueue-config:

    ### Dask jobqueue worker options ###

    cores: 96        # use full node CPU and memory resources
    memory: 90000M   # e.g. $ control show node jwc00n018
    
    processes: 1     # good only for pure Numpy workflows

    local-directory: /tmp
    death-timeout: 60

    extra: ['--host ${SLURMD_NODENAME}.ib.juwels.fzj.de'] # globally visible compute node network location
    interface: null  # don't use this option!

    ### SLURM job script options ####

    shebang: '#!/usr/bin/env bash'
    walltime: '00:15:00'
    log-directory: dask_jobqueue_logs
    name: dask-worker

    # depend on project affiliation
    # should be set manually!
    
    queue: null
    project: null

    # these are automatically set
    # by the Dask worker options above
    
    job-cpu: null
    job-mem: null

    # mandatory for
    # standalone configurations
    
    job-extra: []
    env-extra: []
